{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.status.idle": "2022-10-30T01:38:09.619431Z",
     "shell.execute_reply": "2022-10-30T01:38:09.618806Z",
     "shell.execute_reply.started": "2022-10-30T01:38:06.667584Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numerapi in /opt/conda/envs/saturn/lib/python3.9/site-packages (2.12.5)\n",
      "Requirement already satisfied: pandas>=1.1.0 in /opt/conda/envs/saturn/lib/python3.9/site-packages (from numerapi) (1.3.3)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/envs/saturn/lib/python3.9/site-packages (from numerapi) (7.1.2)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/saturn/lib/python3.9/site-packages (from numerapi) (2.25.1)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/envs/saturn/lib/python3.9/site-packages (from numerapi) (2.8.2)\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/saturn/lib/python3.9/site-packages (from numerapi) (2021.3)\n",
      "Requirement already satisfied: tqdm>=4.29.1 in /opt/conda/envs/saturn/lib/python3.9/site-packages (from numerapi) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/envs/saturn/lib/python3.9/site-packages (from pandas>=1.1.0->numerapi) (1.20.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/saturn/lib/python3.9/site-packages (from python-dateutil->numerapi) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/saturn/lib/python3.9/site-packages (from requests->numerapi) (2021.10.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/saturn/lib/python3.9/site-packages (from requests->numerapi) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/envs/saturn/lib/python3.9/site-packages (from requests->numerapi) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/saturn/lib/python3.9/site-packages (from requests->numerapi) (1.26.7)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "!pip install numerapi\n",
    "from numerapi import NumerAPI\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "\n",
    "TOURNAMENT_NAME= \"first_large\"\n",
    "ERA_COL = \"era\"\n",
    "TARGET_COL = \"target_nomi_v4_20\"\n",
    "DATA_TYPE_COL = \"data_type\"\n",
    "EXAMPLE_PREDS_COL = \"example_preds\"\n",
    "PREDICTION_NAME = \"prediction\"\n",
    "\n",
    "TOP_K_FEATURES = 100\n",
    "\n",
    "napi = NumerAPI()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-10-30T01:38:09.620944Z",
     "iopub.status.busy": "2022-10-30T01:38:09.620685Z",
     "iopub.status.idle": "2022-10-30T01:38:09.624343Z",
     "shell.execute_reply": "2022-10-30T01:38:09.623866Z",
     "shell.execute_reply.started": "2022-10-30T01:38:09.620925Z"
    },
    "id": "ovIL8N5eUTPN",
    "outputId": "9db73529-bf75-4d18-905f-5b51169eab9f"
   },
   "outputs": [],
   "source": [
    "# utilities\n",
    "\n",
    "from utils import load_stuff, save_stuff\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-10-30T01:38:09.625286Z",
     "iopub.status.busy": "2022-10-30T01:38:09.625141Z",
     "iopub.status.idle": "2022-10-30T01:38:09.636055Z",
     "shell.execute_reply": "2022-10-30T01:38:09.635570Z",
     "shell.execute_reply.started": "2022-10-30T01:38:09.625270Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# scoring analysis\n",
    "# Submissions are scored by Spearman correlation\n",
    "def score(df):\n",
    "    return df[[TARGET_COL, PREDICTION_NAME]].corr(method=\"spearman\")[TARGET_COL][PREDICTION_NAME]\n",
    "\n",
    "def spearmanr(target, pred):\n",
    "    return np.corrcoef(\n",
    "        target,\n",
    "        pred.rank(pct=True, method=\"first\")\n",
    "    )[0, 1]\n",
    "\n",
    "def ar1(x):\n",
    "    return np.corrcoef(x[:-1], x[1:])[0,1]\n",
    "\n",
    "def autocorr_penalty(x):\n",
    "    n = len(x)\n",
    "    p = ar1(x)\n",
    "    return np.sqrt(1 + 2*np.sum([((n - i)/n)*p**i for i in range(1,n)]))\n",
    "\n",
    "def smart_sharpe(x):\n",
    "    return np.mean(x)/(np.std(x, ddof=1)*autocorr_penalty(x))\n",
    "\n",
    "def numerai_sharpe(x):\n",
    "    return ((np.mean(x) - 0.010415154) / np.std(x)) * np.sqrt(12)\n",
    "\n",
    "\n",
    "def get_basic_per_era_metrics(df:pd.DataFrame,fig_name=\"per_era_scores.png\") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Some metrics related to per-era scores.\n",
    "    Plots per-era mean correlation with `TARGET_NAME` column\n",
    "\n",
    "    more metrics at: https://forum.numer.ai/t/more-metrics-for-ya/636\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Training or Tournament DataFrame having predictions assigned\n",
    "        at `PREDICTION_NAME` column.\n",
    "\n",
    "    fig_name: str, optional, default:per_era_scores.png\n",
    "        Name for per-era correlation graph to be saved with extension.\n",
    "        prefix will be added to the file name based on `data_type`.\n",
    "\n",
    "    Returns:\n",
    "    ------\n",
    "    pd.Series: Pandas Series having per-era metrics\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    prefix=None\n",
    "    scores = pd.Series(dtype=float)\n",
    "    preds_ = df[PREDICTION_NAME]\n",
    "\n",
    "\n",
    "    #-----------------------------------------------------\n",
    "\n",
    "    #Metric Calculations\n",
    "    print(\"getting per era scores\")\n",
    "    era_scores = df.groupby(\"era\").apply(\n",
    "        lambda x: spearmanr(x[TARGET_COL], x[PREDICTION_NAME]))\n",
    "\n",
    "    era_scores.sort_index(inplace=True)\n",
    "    era_scores.plot(kind=\"bar\")\n",
    "    print(\"performance over time\")\n",
    "    plt.savefig(f\"{prefix}_{fig_name}\")\n",
    "    plt.show()\n",
    "\n",
    "    #-----------------------------------------------------\n",
    "\n",
    "    scores[f\"{prefix}_mean\"] = preds_.mean()\n",
    "    scores[f\"{prefix}_std_dev\"] = preds_.std()\n",
    "    scores[f\"{prefix}_less_than_half\"] = (preds_<0.5).mean()\n",
    "    scores[f\"{prefix}_less_than_mean\"] = (preds_<preds_.mean()).mean()\n",
    "\n",
    "    scores[f\"{prefix}_autocorrelation\"] = ar1(era_scores)\n",
    "    scores[f\"{prefix}_mean correlation\"] = np.mean(era_scores)\n",
    "    scores[f\"{prefix}_Median Correlation\"] = np.median(era_scores)\n",
    "    scores[f\"{prefix}_Variance\"] = np.var(era_scores)\n",
    "    scores[f\"{prefix}_Std. Dev.\"] = np.std(era_scores)\n",
    "    scores[f\"{prefix}_sharpe\"] = np.mean(era_scores)/np.std(era_scores)\n",
    "    scores[f\"{prefix}_smart sharpe\"] = smart_sharpe(era_scores)\n",
    "    scores[f\"{prefix}_Numerai sharpe\"] = numerai_sharpe(era_scores)\n",
    "\n",
    "    print(scores)\n",
    "    del era_scores\n",
    "    del preds_\n",
    "    gc.collect()\n",
    "    return scores\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-10-30T01:38:09.636845Z",
     "iopub.status.busy": "2022-10-30T01:38:09.636709Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-30 01:38:10,281 INFO numerapi.utils: target file already exists\n",
      "2022-10-30 01:38:10,282 INFO numerapi.utils: download complete\n",
      "2022-10-30 01:38:10,748 INFO numerapi.utils: target file already exists\n",
      "2022-10-30 01:38:10,749 INFO numerapi.utils: download complete\n",
      "2022-10-30 01:38:11,152 INFO numerapi.utils: target file already exists\n",
      "2022-10-30 01:38:11,153 INFO numerapi.utils: download complete\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "current_round = napi.get_current_round(tournament=8)  # tournament 8 is the primary Numerai Tournament\n",
    "\n",
    "# Tournament data changes every week so we specify the round in their name. Training\n",
    "# and validation data only change periodically, so no need to download them every time.\n",
    "print('Downloading dataset files...')\n",
    "#napi.download_dataset(\"numerai_training_data.parquet\", \"training_data.parquet\")\n",
    "#napi.download_dataset(\"numerai_tournament_data.parquet\", f\"tournament_data_{current_round}.parquet\")\n",
    "#napi.download_dataset(\"numerai_validation_data.parquet\", f\"validation_data.parquet\")\n",
    "#napi.download_dataset(\"example_validation_predictions.parquet\", \"example_validation_predictions.parquet\")\n",
    "#napi.download_dataset(\"features.json\", \"features.json\")\n",
    "\n",
    "\n",
    "napi.download_dataset(\"v4/train.parquet\",\"training_data.parquet\")\n",
    "napi.download_dataset(\"v4/validation.parquet\",f\"validation_data.parquet\")\n",
    "napi.download_dataset(\"v4/live.parquet\", f\"tournament_data_{current_round}.parquet\")\n",
    "napi.download_dataset(\"v4/validation_example_preds.parquet\",\"example_validation_predictions.parquet\")\n",
    "napi.download_dataset(\"v4/features.json\",\"features.json\")\n",
    "\n",
    "\n",
    "# read in just those features along with era and target columns\n",
    "\n",
    "training_data = pq.read_table('training_data.parquet').to_pandas()\n",
    "\n",
    "features = [ f for f in training_data.columns if f.startswith(\"feature\")]\n",
    "\n",
    "X = training_data[features]\n",
    "Y = training_data[TARGET_COL]\n",
    "\n",
    "\n",
    "\n",
    "# pare down the number of eras to every 4th era\n",
    "# every_4th_era = training_data[ERA_COL].unique()[::4]\n",
    "# training_data = training_data[training_data[ERA_COL].isin(every_4th_era)]\n",
    "\n",
    "\n",
    "# \"garbage collection\" (gc) gets rid of unused data and frees up memory\n",
    "gc.collect()\n",
    "\n",
    "#feature_names = [ f for f in training_data.columns if f.startswith(\"feature\")]\n",
    "\n",
    "model_name = f\"model_target\"\n",
    "print(f\"Checking for existing model '{model_name}'\")\n",
    "model = load_stuff(model_name)\n",
    "selected_features = load_stuff('features')\n",
    "if not model:\n",
    "    print(f\"model not found, creating new one\")\n",
    "    \n",
    "    selector = SelectKBest(f_regression, k = TOP_K_FEATURES)\n",
    "    selector.fit(X, Y)\n",
    "    select = X.columns[selector.get_support()]\n",
    "    selected_features = select.tolist()\n",
    "\n",
    "    read_columns = selected_features + [ERA_COL, DATA_TYPE_COL, TARGET_COL]\n",
    "    training_data = pd.read_parquet('training_data.parquet', columns=read_columns)\n",
    "    \n",
    "    feature_names = [ f for f in training_data.columns if f.startswith(\"feature\")]\n",
    "\n",
    "    X = training_data[feature_names]\n",
    "    Y = training_data[TARGET_COL]\n",
    "\n",
    "    model = Ridge(alpha=0.9)\n",
    "\n",
    "    model.fit(X, Y)\n",
    "    print(f\"saving new model, features: {model_name}\")\n",
    "    save_stuff(model,model_name)\n",
    "    save_stuff(selected_features,'features')\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "print('Reading features of validation and tournament data...')\n",
    "read_columns = selected_features + [ERA_COL, DATA_TYPE_COL, TARGET_COL]\n",
    "\n",
    "validation_data = pq.read_table('validation_data.parquet').to_pandas()\n",
    "tournament_data = pq.read_table(f\"tournament_data_{current_round}.parquet\").to_pandas()\n",
    "\n",
    "target_columns = [col for col in tournament_data if 'target' in col]\n",
    "tournament_data.drop(columns=target_columns, inplace=True)\n",
    "nans_per_col = tournament_data[tournament_data[\"data_type\"] == \"live\"].isna().sum()\n",
    "\n",
    "\n",
    "# check for nans and fill nans\n",
    "if nans_per_col.any():\n",
    "    total_rows = len(tournament_data[tournament_data[\"data_type\"] == \"live\"])\n",
    "    print(f\"Number of nans per column this week: {nans_per_col[nans_per_col > 0]}\")\n",
    "    print(f\"out of {total_rows} total rows\")\n",
    "    print(f\"filling nans with 0.5\")\n",
    "    tournament_data.loc[:, feature_names].fillna(0.5, inplace=True)\n",
    "else:\n",
    "    print(\"No nans in the features this week!\")\n",
    "\n",
    "\n",
    "print('Predicting on validation and tournament data')\n",
    "# double check the feature that the model expects vs what is available to prevent our\n",
    "# pipeline from failing if Numerai adds more data and we don't have time to retrain!\n",
    "#model_expected_features = model.feature_names_in_\n",
    "\n",
    "model_expected_features = selected_features\n",
    "\n",
    "#here we only use top K features, so we don't detect a change in features\n",
    "#if set(model_expected_features) != set(feature_names):\n",
    "#    print(f\"New features are available! Might want to retrain model {model_name}.\")\n",
    "\n",
    "training_data[PREDICTION_NAME] = model.predict(training_data[model_expected_features])\n",
    "validation_data[PREDICTION_NAME] = model.predict(validation_data[model_expected_features])\n",
    "tournament_data[PREDICTION_NAME] = model.predict(tournament_data[model_expected_features])\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "validation_data[PREDICTION_NAME].to_csv(f\"validation_predictions_{current_round}.csv\")\n",
    "tournament_data[PREDICTION_NAME].to_csv(f\"tournament_predictions_{current_round}.csv\")\n",
    "\n",
    "validation_preds = pq.read_table(\"example_validation_predictions.parquet\").to_pandas()\n",
    "validation_data[EXAMPLE_PREDS_COL] = validation_preds[\"prediction\"]\n",
    "\n",
    "\n",
    "train_correlations = training_data.groupby(\"era\").apply(score)\n",
    "print( f\"On training the correlation has mean {train_correlations.mean()} and std {train_correlations.std()}\")\n",
    "\n",
    "# Check the per-era correlations on the validation set\n",
    "\n",
    "validation_correlations = validation_data.groupby(\"era\").apply(score)\n",
    "print(f\"On validation the correlation has mean {validation_correlations.mean()} and std {validation_correlations.std()}\")\n",
    "\n",
    "scores = get_basic_per_era_metrics(validation_data)\n",
    "  \n",
    "\n",
    "print(f'done in {(time.time() - start) / 60} mins')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8rpvmvpjKaFE",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "id = \"OML65REYFDPC5O7N22XCRP44BG2M74XH\"\n",
    "key = \"YSTL455VERL7WZ4D7OQ6XEYEQN2MRCCICBMILNFP3DUZC4MSAS2WSH2MV7ED6WB3\"\n",
    "\n",
    "napi = NumerAPI(public_id=id,secret_key=key)\n",
    "\n",
    "path =  f\"tournament_predictions_{current_round}.csv\"\n",
    "\n",
    "#print('uploading')\n",
    "#napi.upload_predictions(file_path=path,version=2)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "kazutsugi.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
