{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-12-10T04:23:39.229817Z",
     "iopub.status.busy": "2021-12-10T04:23:39.229492Z",
     "iopub.status.idle": "2021-12-10T04:23:42.250385Z",
     "shell.execute_reply": "2021-12-10T04:23:42.249847Z",
     "shell.execute_reply.started": "2021-12-10T04:23:39.229748Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numerapi in /opt/conda/envs/saturn/lib/python3.9/site-packages (2.9.4)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/envs/saturn/lib/python3.9/site-packages (from numerapi) (7.1.2)\n",
      "Requirement already satisfied: pandas>=1.1.0 in /opt/conda/envs/saturn/lib/python3.9/site-packages (from numerapi) (1.3.3)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/saturn/lib/python3.9/site-packages (from numerapi) (2.25.1)\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/saturn/lib/python3.9/site-packages (from numerapi) (2021.3)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/envs/saturn/lib/python3.9/site-packages (from numerapi) (2.8.2)\n",
      "Requirement already satisfied: tqdm>=4.29.1 in /opt/conda/envs/saturn/lib/python3.9/site-packages (from numerapi) (4.62.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/envs/saturn/lib/python3.9/site-packages (from pandas>=1.1.0->numerapi) (1.20.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/saturn/lib/python3.9/site-packages (from python-dateutil->numerapi) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/saturn/lib/python3.9/site-packages (from requests->numerapi) (2021.10.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/envs/saturn/lib/python3.9/site-packages (from requests->numerapi) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/saturn/lib/python3.9/site-packages (from requests->numerapi) (1.26.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/saturn/lib/python3.9/site-packages (from requests->numerapi) (2.10)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "!pip install numerapi\n",
    "from numerapi import NumerAPI\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "\n",
    "TOURNAMENT_NAME= \"first_large\"\n",
    "ERA_COL = \"era\"\n",
    "TARGET_COL = \"target_nomi_20\"\n",
    "DATA_TYPE_COL = \"data_type\"\n",
    "EXAMPLE_PREDS_COL = \"example_preds\"\n",
    "PREDICTION_NAME = \"prediction\"\n",
    "\n",
    "TOP_K_FEATURES = 100\n",
    "\n",
    "napi = NumerAPI()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-12-10T04:23:43.115737Z",
     "iopub.status.busy": "2021-12-10T04:23:43.115444Z",
     "iopub.status.idle": "2021-12-10T04:23:43.119143Z",
     "shell.execute_reply": "2021-12-10T04:23:43.118539Z",
     "shell.execute_reply.started": "2021-12-10T04:23:43.115713Z"
    },
    "id": "ovIL8N5eUTPN",
    "outputId": "9db73529-bf75-4d18-905f-5b51169eab9f"
   },
   "outputs": [],
   "source": [
    "# utilities\n",
    "\n",
    "from utils import load_stuff, save_stuff\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-12-10T04:23:45.667005Z",
     "iopub.status.busy": "2021-12-10T04:23:45.666621Z",
     "iopub.status.idle": "2021-12-10T04:23:45.677991Z",
     "shell.execute_reply": "2021-12-10T04:23:45.677489Z",
     "shell.execute_reply.started": "2021-12-10T04:23:45.666984Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# scoring analysis\n",
    "# Submissions are scored by Spearman correlation\n",
    "def score(df):\n",
    "    return df[[TARGET_COL, PREDICTION_NAME]].corr(method=\"spearman\")[TARGET_COL][PREDICTION_NAME]\n",
    "\n",
    "def spearmanr(target, pred):\n",
    "    return np.corrcoef(\n",
    "        target,\n",
    "        pred.rank(pct=True, method=\"first\")\n",
    "    )[0, 1]\n",
    "\n",
    "def ar1(x):\n",
    "    return np.corrcoef(x[:-1], x[1:])[0,1]\n",
    "\n",
    "def autocorr_penalty(x):\n",
    "    n = len(x)\n",
    "    p = ar1(x)\n",
    "    return np.sqrt(1 + 2*np.sum([((n - i)/n)*p**i for i in range(1,n)]))\n",
    "\n",
    "def smart_sharpe(x):\n",
    "    return np.mean(x)/(np.std(x, ddof=1)*autocorr_penalty(x))\n",
    "\n",
    "def numerai_sharpe(x):\n",
    "    return ((np.mean(x) - 0.010415154) / np.std(x)) * np.sqrt(12)\n",
    "\n",
    "\n",
    "def get_basic_per_era_metrics(df:pd.DataFrame,fig_name=\"per_era_scores.png\") -> pd.Series:\n",
    "    \"\"\"\n",
    "    Some metrics related to per-era scores.\n",
    "    Plots per-era mean correlation with `TARGET_NAME` column\n",
    "\n",
    "    more metrics at: https://forum.numer.ai/t/more-metrics-for-ya/636\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Training or Tournament DataFrame having predictions assigned\n",
    "        at `PREDICTION_NAME` column.\n",
    "\n",
    "    fig_name: str, optional, default:per_era_scores.png\n",
    "        Name for per-era correlation graph to be saved with extension.\n",
    "        prefix will be added to the file name based on `data_type`.\n",
    "\n",
    "    Returns:\n",
    "    ------\n",
    "    pd.Series: Pandas Series having per-era metrics\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    prefix=None\n",
    "    scores = pd.Series(dtype=float)\n",
    "    preds_ = df[PREDICTION_NAME]\n",
    "\n",
    "\n",
    "    #-----------------------------------------------------\n",
    "\n",
    "    #Metric Calculations\n",
    "    print(\"getting per era scores\")\n",
    "    era_scores = df.groupby(\"era\").apply(\n",
    "        lambda x: spearmanr(x[TARGET_COL], x[PREDICTION_NAME]))\n",
    "\n",
    "    era_scores.sort_index(inplace=True)\n",
    "    era_scores.plot(kind=\"bar\")\n",
    "    print(\"performance over time\")\n",
    "    plt.savefig(f\"{prefix}_{fig_name}\")\n",
    "    plt.show()\n",
    "\n",
    "    #-----------------------------------------------------\n",
    "\n",
    "    scores[f\"{prefix}_mean\"] = preds_.mean()\n",
    "    scores[f\"{prefix}_std_dev\"] = preds_.std()\n",
    "    scores[f\"{prefix}_less_than_half\"] = (preds_<0.5).mean()\n",
    "    scores[f\"{prefix}_less_than_mean\"] = (preds_<preds_.mean()).mean()\n",
    "\n",
    "    scores[f\"{prefix}_autocorrelation\"] = ar1(era_scores)\n",
    "    scores[f\"{prefix}_mean correlation\"] = np.mean(era_scores)\n",
    "    scores[f\"{prefix}_Median Correlation\"] = np.median(era_scores)\n",
    "    scores[f\"{prefix}_Variance\"] = np.var(era_scores)\n",
    "    scores[f\"{prefix}_Std. Dev.\"] = np.std(era_scores)\n",
    "    scores[f\"{prefix}_sharpe\"] = np.mean(era_scores)/np.std(era_scores)\n",
    "    scores[f\"{prefix}_smart sharpe\"] = smart_sharpe(era_scores)\n",
    "    scores[f\"{prefix}_Numerai sharpe\"] = numerai_sharpe(era_scores)\n",
    "\n",
    "    print(scores)\n",
    "    del era_scores\n",
    "    del preds_\n",
    "    gc.collect()\n",
    "    return scores\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2021-12-10T04:23:47.137445Z",
     "iopub.status.busy": "2021-12-10T04:23:47.136832Z",
     "iopub.status.idle": "2021-12-10T04:24:25.898453Z",
     "shell.execute_reply": "2021-12-10T04:24:25.897555Z",
     "shell.execute_reply.started": "2021-12-10T04:23:47.137416Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-10 04:23:47,967 INFO numerapi.utils: starting download\n",
      "training_data.parquet: 1.01GB [00:35, 28.6MB/s]                            \n",
      "2021-12-10 04:24:24,133 INFO numerapi.utils: target file already exists\n",
      "2021-12-10 04:24:24,134 INFO numerapi.utils: download complete\n",
      "2021-12-10 04:24:24,703 INFO numerapi.utils: target file already exists\n",
      "2021-12-10 04:24:24,703 INFO numerapi.utils: download complete\n",
      "2021-12-10 04:24:25,238 INFO numerapi.utils: target file already exists\n",
      "2021-12-10 04:24:25,239 INFO numerapi.utils: download complete\n",
      "2021-12-10 04:24:25,729 INFO numerapi.utils: target file already exists\n",
      "2021-12-10 04:24:25,730 INFO numerapi.utils: download complete\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1971/537460838.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# read in just those features along with era and target columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtraining_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training_data.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"feature\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pq' is not defined"
     ]
    }
   ],
   "source": [
    "current_round = napi.get_current_round(tournament=8)  # tournament 8 is the primary Numerai Tournament\n",
    "\n",
    "# Tournament data changes every week so we specify the round in their name. Training\n",
    "# and validation data only change periodically, so no need to download them every time.\n",
    "print('Downloading dataset files...')\n",
    "napi.download_dataset(\"numerai_training_data.parquet\", \"training_data.parquet\")\n",
    "napi.download_dataset(\"numerai_tournament_data.parquet\", f\"tournament_data_{current_round}.parquet\")\n",
    "napi.download_dataset(\"numerai_validation_data.parquet\", f\"validation_data.parquet\")\n",
    "napi.download_dataset(\"example_validation_predictions.parquet\", \"example_validation_predictions.parquet\")\n",
    "napi.download_dataset(\"features.json\", \"features.json\")\n",
    "\n",
    "\n",
    "\n",
    "# read in just those features along with era and target columns\n",
    "\n",
    "training_data = pq.read_table('training_data.parquet').to_pandas()\n",
    "\n",
    "features = [ f for f in training_data.columns if f.startswith(\"feature\")]\n",
    "\n",
    "X = training_data[features]\n",
    "Y = training_data[TARGET_COL]\n",
    "\n",
    "\n",
    "\n",
    "# pare down the number of eras to every 4th era\n",
    "# every_4th_era = training_data[ERA_COL].unique()[::4]\n",
    "# training_data = training_data[training_data[ERA_COL].isin(every_4th_era)]\n",
    "\n",
    "\n",
    "# \"garbage collection\" (gc) gets rid of unused data and frees up memory\n",
    "gc.collect()\n",
    "\n",
    "#feature_names = [ f for f in training_data.columns if f.startswith(\"feature\")]\n",
    "\n",
    "model_name = f\"model_target\"\n",
    "print(f\"Checking for existing model '{model_name}'\")\n",
    "model = load_stuff(model_name)\n",
    "selected_features = load_stuff('features')\n",
    "if not model:\n",
    "    print(f\"model not found, creating new one\")\n",
    "    \n",
    "    selector = SelectKBest(f_regression, k = TOP_K_FEATURES)\n",
    "    selector.fit(X, Y)\n",
    "    select = X.columns[selector.get_support()]\n",
    "    selected_features = select.tolist()\n",
    "\n",
    "    read_columns = selected_features + [ERA_COL, DATA_TYPE_COL, TARGET_COL]\n",
    "    training_data = pd.read_parquet('training_data.parquet', columns=read_columns)\n",
    "    \n",
    "    feature_names = [ f for f in training_data.columns if f.startswith(\"feature\")]\n",
    "\n",
    "    X = training_data[feature_names]\n",
    "    Y = training_data[TARGET_COL]\n",
    "\n",
    "    model = Ridge(alpha=0.9)\n",
    "\n",
    "    model.fit(X, Y)\n",
    "    print(f\"saving new model, features: {model_name}\")\n",
    "    save_stuff(model,model_name)\n",
    "    save_stuff(selected_features,'features')\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "print('Reading features of validation and tournament data...')\n",
    "read_columns = selected_features + [ERA_COL, DATA_TYPE_COL, TARGET_COL]\n",
    "\n",
    "validation_data = pq.read_table('validation_data.parquet').to_pandas()\n",
    "tournament_data = pq.read_table(f\"tournament_data_{current_round}.parquet\").to_pandas()\n",
    "\n",
    "target_columns = [col for col in tournament_data if 'target' in col]\n",
    "tournament_data.drop(columns=target_columns, inplace=True)\n",
    "nans_per_col = tournament_data[tournament_data[\"data_type\"] == \"live\"].isna().sum()\n",
    "\n",
    "\n",
    "# check for nans and fill nans\n",
    "if nans_per_col.any():\n",
    "    total_rows = len(tournament_data[tournament_data[\"data_type\"] == \"live\"])\n",
    "    print(f\"Number of nans per column this week: {nans_per_col[nans_per_col > 0]}\")\n",
    "    print(f\"out of {total_rows} total rows\")\n",
    "    print(f\"filling nans with 0.5\")\n",
    "    tournament_data.loc[:, feature_names].fillna(0.5, inplace=True)\n",
    "else:\n",
    "    print(\"No nans in the features this week!\")\n",
    "\n",
    "\n",
    "print('Predicting on validation and tournament data')\n",
    "# double check the feature that the model expects vs what is available to prevent our\n",
    "# pipeline from failing if Numerai adds more data and we don't have time to retrain!\n",
    "#model_expected_features = model.feature_names_in_\n",
    "\n",
    "model_expected_features = selected_features\n",
    "\n",
    "#here we only use top K features, so we don't detect a change in features\n",
    "#if set(model_expected_features) != set(feature_names):\n",
    "#    print(f\"New features are available! Might want to retrain model {model_name}.\")\n",
    "\n",
    "training_data[PREDICTION_NAME] = model.predict(training_data[model_expected_features])\n",
    "validation_data[PREDICTION_NAME] = model.predict(validation_data[model_expected_features])\n",
    "tournament_data[PREDICTION_NAME] = model.predict(tournament_data[model_expected_features])\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "validation_data[PREDICTION_NAME].to_csv(f\"validation_predictions_{current_round}.csv\")\n",
    "tournament_data[PREDICTION_NAME].to_csv(f\"tournament_predictions_{current_round}.csv\")\n",
    "\n",
    "validation_preds = pq.read_table(\"example_validation_predictions.parquet\").to_pandas()\n",
    "validation_data[EXAMPLE_PREDS_COL] = validation_preds[\"prediction\"]\n",
    "\n",
    "\n",
    "train_correlations = training_data.groupby(\"era\").apply(score)\n",
    "print( f\"On training the correlation has mean {train_correlations.mean()} and std {train_correlations.std()}\")\n",
    "\n",
    "# Check the per-era correlations on the validation set\n",
    "\n",
    "validation_correlations = validation_data.groupby(\"era\").apply(score)\n",
    "print(f\"On validation the correlation has mean {validation_correlations.mean()} and std {validation_correlations.std()}\")\n",
    "\n",
    "scores = get_basic_per_era_metrics(validation_data)\n",
    "  \n",
    "\n",
    "print(f'done in {(time.time() - start) / 60} mins')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T23:42:08.337877Z",
     "iopub.status.busy": "2021-11-07T23:42:08.337563Z",
     "iopub.status.idle": "2021-11-07T23:42:08.341113Z",
     "shell.execute_reply": "2021-11-07T23:42:08.340586Z",
     "shell.execute_reply.started": "2021-11-07T23:42:08.337853Z"
    },
    "id": "8rpvmvpjKaFE",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "id = \"OML65REYFDPC5O7N22XCRP44BG2M74XH\"\n",
    "key = \"YSTL455VERL7WZ4D7OQ6XEYEQN2MRCCICBMILNFP3DUZC4MSAS2WSH2MV7ED6WB3\"\n",
    "\n",
    "napi = NumerAPI(public_id=id,secret_key=key)\n",
    "\n",
    "path =  f\"tournament_predictions_{current_round}.csv\"\n",
    "\n",
    "#print('uploading')\n",
    "#napi.upload_predictions(file_path=path,version=2)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "kazutsugi.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
